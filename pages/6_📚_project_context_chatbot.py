import os
import utils
import streamlit as st
from streaming import StreamHandler
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from loguru import logger
from config.settings import settings

st.set_page_config(page_title="í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì±—ë´‡", page_icon="ğŸ“š")
st.header('í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì±—ë´‡')
st.write('í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.')

class ProjectContextChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
        self.context = self.load_project_context()
        self.chain = self.setup_chain()
    
    def load_project_context(self):
        context = ""
        directories = ['jobdescription', 'progress', 'todo', 'retrospective']
        for directory in directories:
            path = os.path.join(os.getcwd(), directory)
            if os.path.exists(path):
                for filename in os.listdir(path):
                    if filename.endswith('.md'):
                        with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:
                            context += f"\n\n{filename}:\n{file.read()}"
        return context

    def setup_chain(self):
        memory = ConversationBufferMemory()
        chain = ConversationChain(
            llm=self.llm, 
            memory=memory, 
            verbose=True
        )
        return chain
    
    @utils.enable_chat_history
    def main(self):
        # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í‘œì‹œ
        with st.expander("í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´", expanded=False):
            st.text(self.context)

        user_query = st.chat_input(placeholder="í”„ë¡œì íŠ¸ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")
        
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                try:
                    # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
                    full_query = f"í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸:\n{self.context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_query}"
                    result = self.chain.invoke(
                        {"input": full_query},
                        {"callbacks": [st_cb]}
                    )
                    response = result["response"]
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    logger.info(f"ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
                    logger.info(f"ì±—ë´‡ ì‘ë‹µ: {response}")
                except Exception as e:
                    error_msg = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                    st.error(error_msg)
                    logger.error(error_msg)

if __name__ == "__main__":
    st.sidebar.title("ì„¤ì •")
    model = st.sidebar.selectbox("LLM ëª¨ë¸ ì„ íƒ", [settings.DEFAULT_MODEL, "ë‹¤ë¥¸ëª¨ë¸1", "ë‹¤ë¥¸ëª¨ë¸2"])
    temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.7)
    
    obj = ProjectContextChatbot()
    obj.main()