import os
import utils
import streamlit as st
from streaming import StreamHandler
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import DocArrayInMemorySearch
from langchain_text_splitters import RecursiveCharacterTextSplitter
from loguru import logger
from config.settings import settings

st.set_page_config(page_title="ë¬¸ì„œ ì±—ë´‡", page_icon="ğŸ“„")
st.header('ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡ (ê¸°ë³¸ RAG)')
st.write('ì‚¬ìš©ì ì •ì˜ ë¬¸ì„œì— ì ‘ê·¼í•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ì¡°í•´ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

class CustomDataChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()

    def save_file(self, file):
        folder = 'tmp'
        if not os.path.exists(folder):
            os.makedirs(folder)
        
        file_path = f'./{folder}/{file.name}'
        with open(file_path, 'wb') as f:
            f.write(file.getvalue())
        return file_path

    @st.spinner('ë¬¸ì„œ ë¶„ì„ ì¤‘..')
    def setup_qa_chain(self, uploaded_files):
        try:
            # ë¬¸ì„œ ë¡œë“œ
            docs = []
            for file in uploaded_files:
                file_path = self.save_file(file)
                loader = PyPDFLoader(file_path)
                docs.extend(loader.load())
                os.remove(file_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            
            # ë¬¸ì„œ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            splits = text_splitter.split_documents(docs)

            # ì„ë² ë”© ìƒì„± ë° ë²¡í„° DB ì €ì¥
            embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")
            vectordb = DocArrayInMemorySearch.from_documents(splits, embeddings)

            # ê²€ìƒ‰ê¸° ì •ì˜
            retriever = vectordb.as_retriever(
                search_type='mmr',
                search_kwargs={'k': self.k, 'fetch_k': self.fetch_k}
            )

            # ì»¨í…ìŠ¤íŠ¸ ëŒ€í™”ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ì„¤ì •        
            memory = ConversationBufferMemory(
                memory_key='chat_history',
                output_key='answer',
                return_messages=True
            )

            # LLM ë° QA ì²´ì¸ ì„¤ì •
            qa_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=retriever,
                memory=memory,
                return_source_documents=True,
                verbose=True
            )
            return qa_chain
        except Exception as e:
            logger.error(f"QA ì²´ì¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    @utils.enable_chat_history
    def main(self):
        # ì‚¬ìš©ì ì…ë ¥
        uploaded_files = st.sidebar.file_uploader(label='PDF íŒŒì¼ ì—…ë¡œë“œ', type=['pdf'], accept_multiple_files=True)
        if not uploaded_files:
            st.error("ê³„ì†í•˜ë ¤ë©´ PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            st.stop()

        # ì‚¬ìš©ì ì„¤ì •
        self.k = st.sidebar.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜", 1, 5, 2)
        self.fetch_k = st.sidebar.slider("í›„ë³´ ë¬¸ì„œ ìˆ˜", 1, 10, 4)

        user_query = st.chat_input(placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")

        if uploaded_files and user_query:
            try:
                qa_chain = self.setup_qa_chain(uploaded_files)
                utils.display_msg(user_query, 'user')

                with st.chat_message("assistant"):
                    st_cb = StreamHandler(st.empty())
                    result = qa_chain.invoke(
                        {"question": user_query},
                        {"callbacks": [st_cb]}
                    )
                    response = result["answer"]
                    st.session_state.messages.append({"role": "assistant", "content": response})

                    # ì°¸ì¡° í‘œì‹œ
                    for idx, doc in enumerate(result['source_documents'], 1):
                        filename = os.path.basename(doc.metadata['source'])
                        page_num = doc.metadata['page']
                        ref_title = f":blue[ì°¸ì¡° {idx}: *{filename} - í˜ì´ì§€ {page_num}*]"
                        with st.popover(ref_title):
                            st.caption(doc.page_content)

                logger.info(f"ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
                logger.info(f"ì±—ë´‡ ì‘ë‹µ: {response}")
            except Exception as e:
                error_msg = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                st.error(error_msg)
                logger.error(error_msg)

if __name__ == "__main__":
    obj = CustomDataChatbot()
    obj.main()