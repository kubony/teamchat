File: .gitignore
## Frontend
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.js

# testing
/coverage

# next.js
*.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local
.env.dev
.env.prod
.env.test

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

.env.local
.env.development.local
.env.test.local
.env.production.local


#amplify-do-not-edit-begin
amplify/\#current-cloud-backend
amplify/.config/local-*
amplify/logs
amplify/mock-data
amplify/mock-api-resources
amplify/backend/amplify-meta.json
amplify/backend/.temp
node_modules/
aws-exports.js
awsconfiguration.json
amplifyconfiguration.json
amplifyconfiguration.dart
amplify-build-config.json
amplify-gradle-config.json
amplifytools.xcconfig
.secret-*
**.sample
#amplify-do-not-edit-end

#intellij env
.idea/

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

/creds
/logs
/projects
/ai/knowledge
*.sqlite
*_cache*
/scripts/*.txt
utils/project_info/project_log.txt
docs_gen/**/*.txt



File: README.md
# Chatbot Implementations with Langchain + Streamlit

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/shashankdeshpande/langchain-chatbot?quickstart=1)

Langchain is a powerful framework designed to streamline the development of applications using Language Models (LLMs). \
It provides a comprehensive integration of various components, simplifying the process of assembling them to create robust applications.

## üí¨ Sample chatbot use cases
Here are a few examples of chatbot implementations using Langchain and Streamlit:
-  **Basic Chatbot** \
  Engage in interactive conversations with the LLM.

- **Context aware chatbot** \
  A chatbot that remembers previous conversations and provides responses accordingly.

-  **Chatbot with Internet Access** \
  An internet-enabled chatbot capable of answering user queries about recent events.

-  **Chat with your documents** \
  Empower the chatbot with the ability to access custom documents, enabling it to provide answers to user queries based on the referenced information.

-  **Chat with SQL database** \
  Enable the chatbot to interact with a SQL database through simple, conversational commands.

## <img src="https://streamlit.io/images/brand/streamlit-mark-color.png" width="40" height="22"> Streamlit App
Created a multi-page streamlit app containing all sample chatbot use cases. \
You can access this app through this link: [langchain-chatbot.streamlit.app](https://langchain-chatbot.streamlit.app)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://langchain-chatbot.streamlit.app/)

## üñ•Ô∏è Running locally
```shell
# Run main streamlit app
$ streamlit run Home.py
```

## üíÅ Contributing
Planning to add more chatbot examples over time. PRs are welcome.

File: Home.py
import streamlit as st

st.set_page_config(
    page_title="Langchain Chatbot",
    page_icon='üí¨',
    layout='wide'
)

st.header("Chatbot Implementations with Langchain")
st.write("""
[![view source code ](https://img.shields.io/badge/GitHub%20Repository-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot)
[![linkedin ](https://img.shields.io/badge/Shashank%20Deshpande-blue?logo=linkedin&color=gray)](https://www.linkedin.com/in/shashank-deshpande/)
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Flangchain-chatbot.streamlit.app&label=Visitors&labelColor=%235d5d5d&countColor=%231e7ebf&style=flat)
""")
st.write("""
Langchain is a powerful framework designed to streamline the development of applications using Language Models (LLMs). It provides a comprehensive integration of various components, simplifying the process of assembling them to create robust applications.

Leveraging the power of Langchain, the creation of chatbots becomes effortless. Here are a few examples of chatbot implementations catering to different use cases:

- **Basic Chatbot**: Engage in interactive conversations with the LLM.
- **Context aware chatbot**: A chatbot that remembers previous conversations and provides responses accordingly.
- **Chatbot with Internet Access**: An internet-enabled chatbot capable of answering user queries about recent events.
- **Chat with your documents**: Empower the chatbot with the ability to access custom documents, enabling it to provide answers to user queries based on the referenced information.
- **Chat with SQL database**: Enable the chatbot to interact with a SQL database through simple, conversational commands.

To explore sample usage of each chatbot, please navigate to the corresponding chatbot section.
""")

File: streaming.py
from langchain_core.callbacks import BaseCallbackHandler

class StreamHandler(BaseCallbackHandler):
    
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.container.markdown(self.text)

File: LICENSE
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


File: requirements.txt
langchain==0.2.9
langchain_community==0.2.7
langchain_core==0.2.21
langchain_openai==0.1.17
langchain_text_splitters==0.2.2
openai==1.35.15
SQLAlchemy==2.0.31
streamlit==1.36.0
duckduckgo-search==6.2.1
pypdf==4.3.0
sentence-transformers==3.0.1
docarray==0.40.0


File: utils.py
import os
import openai
import streamlit as st
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama

#decorator
def enable_chat_history(func):
    if os.environ.get("OPENAI_API_KEY"):

        # to clear chat history after swtching chatbot
        current_page = func.__qualname__
        if "current_page" not in st.session_state:
            st.session_state["current_page"] = current_page
        if st.session_state["current_page"] != current_page:
            try:
                st.cache_resource.clear()
                del st.session_state["current_page"]
                del st.session_state["messages"]
            except:
                pass

        # to show chat history on ui
        if "messages" not in st.session_state:
            st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]
        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    def execute(*args, **kwargs):
        func(*args, **kwargs)
    return execute

def display_msg(msg, author):
    """Method to display message on the UI

    Args:
        msg (str): message to display
        author (str): author of the message -user/assistant
    """
    st.session_state.messages.append({"role": author, "content": msg})
    st.chat_message(author).write(msg)

def choose_custom_openai_key():
    openai_api_key = st.sidebar.text_input(
        label="OpenAI API Key",
        type="password",
        placeholder="sk-...",
        key="SELECTED_OPENAI_API_KEY"
        )
    if not openai_api_key:
        st.error("Please add your OpenAI API key to continue.")
        st.info("Obtain your key from this link: https://platform.openai.com/account/api-keys")
        st.stop()

    model = "gpt-4o-mini"
    try:
        client = openai.OpenAI(api_key=openai_api_key)
        available_models = [{"id": i.id, "created":datetime.fromtimestamp(i.created)} for i in client.models.list() if str(i.id).startswith("gpt")]
        available_models = sorted(available_models, key=lambda x: x["created"])
        available_models = [i["id"] for i in available_models]

        model = st.sidebar.selectbox(
            label="Model",
            options=available_models,
            key="SELECTED_OPENAI_MODEL"
        )
    except openai.AuthenticationError as e:
        st.error(e.body["message"])
        st.stop()
    except Exception as e:
        print(e)
        st.error("Something went wrong. Please try again later.")
        st.stop()
    return model, openai_api_key

def configure_llm():
    available_llms = ["gpt-4o-mini","llama3:8b","use your openai api key"]
    llm_opt = st.sidebar.radio(
        label="LLM",
        options=available_llms,
        key="SELECTED_LLM"
        )

    if llm_opt == "llama3:8b":
        llm = ChatOllama(model="llama3", base_url=st.secrets["OLLAMA_ENDPOINT"])
    elif llm_opt == "gpt-4o-mini":
        llm = ChatOpenAI(model_name=llm_opt, temperature=0, streaming=True, api_key=st.secrets["OPENAI_API_KEY"])
    else:
        model, openai_api_key = choose_custom_openai_key()
        llm = ChatOpenAI(model_name=model, temperature=0, streaming=True, api_key=openai_api_key)
    return llm

def sync_st_session():
    for k, v in st.session_state.items():
        st.session_state[k] = v

File: tools/scripts/project_file_scanner.py
import os
import fnmatch
import sys

def get_ignore_patterns(file_path):
    patterns = []
    if os.path.exists(file_path):
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.append(line)
    return patterns

def get_gitignore_patterns(base_dir):
    patterns = []
    gitignore_paths = [
        os.path.join(base_dir, '.gitignore'),
        os.path.join(base_dir, 'app', 'frontend', '.gitignore'),
        os.path.join(base_dir, 'ios', '.gitignore'),
        os.path.join(base_dir, 'android', '.gitignore')
    ]
    for gitignore_path in gitignore_paths:
        patterns.extend(get_ignore_patterns(gitignore_path))
    return patterns

def should_include(file_path, patterns):
    for pattern in patterns:
        if pattern.startswith('/'):
            if fnmatch.fnmatch(file_path, pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(file_path + '/', pattern):
                return False
        else:
            if fnmatch.fnmatch(file_path, pattern) or fnmatch.fnmatch(os.path.basename(file_path), pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(os.path.basename(file_path) + '/', pattern):
                return False
    return True

def collect_project_files(base_dir='.'):
    script_dir = os.path.abspath(base_dir)
    print(script_dir)
    utils_dir = os.path.join(script_dir, 'tools/data')
    print(utils_dir)
    output_dir = os.path.join(utils_dir, 'scanned_project_files')
    print(output_dir)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    overview_filename = os.path.join(output_dir, 'tree.txt')
    detailed_filename = os.path.join(output_dir, 'codes.txt')
    log_filename = os.path.join(output_dir, 'log.txt')
    additional_ignore_path = os.path.join(utils_dir, 'additional_ignore.txt')

    gitignore_patterns = get_gitignore_patterns(base_dir)
    additional_ignore_patterns = get_ignore_patterns(additional_ignore_path)
    patterns = list(set(gitignore_patterns + additional_ignore_patterns))

    open(overview_filename, 'w').close()
    open(detailed_filename, 'w').close()
    open(log_filename, 'w').close()

    with open(overview_filename, 'a', encoding='utf-8') as overview_file, \
         open(detailed_filename, 'a', encoding='utf-8') as detailed_file, \
         open(log_filename, 'a', encoding='utf-8') as logfile:
         
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, script_dir)
                
                if should_include(relative_path, patterns):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as infile:
                            detailed_file.write(f"File: {relative_path}\n")
                            detailed_file.write(infile.read())
                            detailed_file.write("\n\n")
                            logfile.write(f"Including file: {relative_path}\n")
                    except UnicodeDecodeError as e:
                        logfile.write(f"Could not read file (encoding issue) {file_path}: {e}\n")
                    except Exception as e:
                        logfile.write(f"Could not read file {file_path}: {e}\n")
                else:
                    logfile.write(f"Excluded by pattern: {relative_path}\n")
        
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            relative_path = os.path.relpath(root, script_dir)
            if should_include(relative_path, patterns):
                overview_file.write(f"Directory: {relative_path}\n")
                overview_file.write("Contains:\n")
                for dir in dirs:
                    overview_file.write(f"- {dir}\n")
                for file in files:
                    file_relative_path = os.path.relpath(os.path.join(root, file), script_dir)
                    if should_include(file_relative_path, patterns):
                        overview_file.write(f"- {file}\n")
                overview_file.write("\n")
            else:
                logfile.write(f"Excluded directory by pattern: {relative_path}\n")

if __name__ == "__main__":
    base_dir = sys.argv[1] if len(sys.argv) > 1 else '.'
    collect_project_files(base_dir)

File: tools/scripts/codes_by_folders.py
import os
import fnmatch
import shutil
from pathlib import Path

def get_gitignore_patterns(base_dir):
    gitignore_path = Path(base_dir) / '.gitignore'
    patterns = []
    if gitignore_path.exists():
        with open(gitignore_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    if not line.startswith('/'):
                        line = f'**/{line}'
                    patterns.append(line)
    return patterns

def is_ignored(path, base_path, patterns):
    rel_path = path.relative_to(base_path)
    for pattern in patterns:
        if fnmatch.fnmatch(str(rel_path), pattern) or fnmatch.fnmatch(str(rel_path) + '/', pattern):
            return True
    return False

def is_code_file(file_path):
    code_extensions = ['.py', '.dart', '.js', '.ts']  # ÌïÑÏöîÌïú ÌååÏùº ÌôïÏû•ÏûêÎ•º Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî
    return file_path.suffix in code_extensions

def combine_code_files(source_dir, dest_dir):
    source_path = Path(source_dir).resolve()
    dest_path = Path(dest_dir).resolve()
    
    if not source_path.exists():
        raise FileNotFoundError(f"Source directory '{source_path}' does not exist.")
    
    dest_path.mkdir(parents=True, exist_ok=True)
    
    ignore_patterns = get_gitignore_patterns(source_path)
    
    all_included_files = []

    # Î®ºÏ†Ä root Ìè¥ÎçîÏùò Ï£ºÏöî ÌååÏùºÎì§ÏùÑ Ï≤òÎ¶¨Ìï©ÎãàÎã§
    for file in source_path.glob('*'):
        if file.is_file() and is_code_file(file) and not is_ignored(file, source_path, ignore_patterns):
            shutil.copy2(file, dest_path)
            all_included_files.append(file.name)

    for root, dirs, files in os.walk(source_path):
        rel_path = Path(root).relative_to(source_path)
        current_path = source_path / rel_path
        
        dirs[:] = [d for d in dirs if not is_ignored(current_path / d, source_path, ignore_patterns)]
        
        if not is_ignored(current_path, source_path, ignore_patterns):
            (dest_path / rel_path).mkdir(parents=True, exist_ok=True)
            
            combined_code = f"Combined code for {rel_path}\n\n"
            included_files = []
            
            for file in files:
                file_path = current_path / file
                if is_code_file(file_path) and not is_ignored(file_path, source_path, ignore_patterns):
                    rel_file_path = file_path.relative_to(source_path)
                    included_files.append(str(rel_file_path))
                    all_included_files.append(str(rel_file_path))
                    combined_code += f"File: {rel_file_path}\n"
                    with open(file_path, 'r', encoding='utf-8') as f:
                        combined_code += f.read()
                    combined_code += "\n\n"
            
            # Write combined code
            with open(dest_path / rel_path / 'combined_code.txt', 'w', encoding='utf-8') as f:
                f.write(combined_code)
            
            # Write list of included files for this directory
            with open(dest_path / rel_path / 'included_files.txt', 'w', encoding='utf-8') as f:
                for file in included_files:
                    f.write(f"{file}\n")

    # Write list of all included files in the root directory
    with open(dest_path / 'all_included_files.txt', 'w', encoding='utf-8') as f:
        for file in sorted(all_included_files):
            f.write(f"{file}\n")

    print(f"Directory structure and combined code created in '{dest_path}'")

# Ïã§Ìñâ
if __name__ == "__main__":
    source_directory = "."  # ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨Î•º rootÎ°ú ÏÑ§Ï†ï
    destination_directory = "docs_gen"  # docs_gen Ìè¥Îçî Í≤ΩÎ°ú
    
    combine_code_files(source_directory, destination_directory)

File: tools/scripts/db_scanner.py
import os
import json
from datetime import datetime, timezone
from loguru import logger
from typing import Optional, Dict, Any
from dotenv import load_dotenv
from sqlalchemy import create_engine, inspect

# .env ÌååÏùºÏóêÏÑú ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú
load_dotenv('.env.dev')

# ÌôòÍ≤Ω Î≥ÄÏàòÏóêÏÑú ÏÑ§Ï†ï Í∞ÄÏ†∏Ïò§Í∏∞
class Settings:
    postgres_user = os.getenv("POSTGRES_USER")
    postgres_password = os.getenv("POSTGRES_PASSWORD")
    postgres_host = os.getenv("POSTGRES_HOST")
    postgres_port = os.getenv("POSTGRES_PORT")
    postgres_dbname = os.getenv("POSTGRES_DBNAME")

settings = Settings()

# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Î¨∏ÏûêÏó¥ ÏÉùÏÑ±
DATABASE_URL = f"postgresql://{settings.postgres_user}:{settings.postgres_password}@{settings.postgres_host}:{settings.postgres_port}/{settings.postgres_dbname}"

def fetch_db_info(engine):
    db_info = {}
    inspector = inspect(engine)
    
    for schema in inspector.get_schema_names():
        if schema not in ['information_schema', 'pg_catalog']:
            db_info[schema] = {}
            for table_name in inspector.get_table_names(schema=schema):
                db_info[schema][table_name] = {
                    "columns": [],
                    "foreign_keys": [],
                    "primary_key": []
                }
                
                # Ïª¨Îüº Ï†ïÎ≥¥
                for column in inspector.get_columns(table_name, schema=schema):
                    db_info[schema][table_name]["columns"].append({
                        "column_name": column['name'],
                        "data_type": str(column['type'])
                    })
                
                # Ïô∏Îûò ÌÇ§ Ï†ïÎ≥¥
                for fk in inspector.get_foreign_keys(table_name, schema=schema):
                    db_info[schema][table_name]["foreign_keys"].append({
                        "constrained_columns": fk['constrained_columns'],
                        "referred_schema": fk['referred_schema'],
                        "referred_table": fk['referred_table'],
                        "referred_columns": fk['referred_columns']
                    })
                
                # Í∏∞Î≥∏ ÌÇ§ Ï†ïÎ≥¥
                pk = inspector.get_pk_constraint(table_name, schema=schema)
                if pk and 'constrained_columns' in pk:
                    db_info[schema][table_name]["primary_key"] = pk['constrained_columns']
    
    return db_info

def save_to_json(data, filename):
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def scan_and_save_db_info(engine):
    db_info = fetch_db_info(engine)
    save_to_json(db_info, 'tools/data/configs/database_schema.json')
    return db_info

def main():
    logger.info("Starting database schema scan")
    
    try:
        engine = create_engine(DATABASE_URL)
        db_info = scan_and_save_db_info(engine)
        logger.info(f"Database schema saved to database_schema.json")
        logger.info(f"Scanned {len(db_info)} schemas")
        for schema, tables in db_info.items():
            logger.info(f"Schema '{schema}' contains {len(tables)} tables")
    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
    
    logger.info("Database schema scan completed")

if __name__ == "__main__":
    main()

File: tools/data/scanned_project_files/log.txt


File: tools/data/scanned_project_files/codes.txt
File: .gitignore
## Frontend
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.js

# testing
/coverage

# next.js
*.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local
.env.dev
.env.prod
.env.test

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

.env.local
.env.development.local
.env.test.local
.env.production.local


#amplify-do-not-edit-begin
amplify/\#current-cloud-backend
amplify/.config/local-*
amplify/logs
amplify/mock-data
amplify/mock-api-resources
amplify/backend/amplify-meta.json
amplify/backend/.temp
node_modules/
aws-exports.js
awsconfiguration.json
amplifyconfiguration.json
amplifyconfiguration.dart
amplify-build-config.json
amplify-gradle-config.json
amplifytools.xcconfig
.secret-*
**.sample
#amplify-do-not-edit-end

#intellij env
.idea/

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

/creds
/logs
/projects
/ai/knowledge
*.sqlite
*_cache*
/scripts/*.txt
utils/project_info/project_log.txt
docs_gen/**/*.txt



File: README.md
# Chatbot Implementations with Langchain + Streamlit

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/shashankdeshpande/langchain-chatbot?quickstart=1)

Langchain is a powerful framework designed to streamline the development of applications using Language Models (LLMs). \
It provides a comprehensive integration of various components, simplifying the process of assembling them to create robust applications.

## üí¨ Sample chatbot use cases
Here are a few examples of chatbot implementations using Langchain and Streamlit:
-  **Basic Chatbot** \
  Engage in interactive conversations with the LLM.

- **Context aware chatbot** \
  A chatbot that remembers previous conversations and provides responses accordingly.

-  **Chatbot with Internet Access** \
  An internet-enabled chatbot capable of answering user queries about recent events.

-  **Chat with your documents** \
  Empower the chatbot with the ability to access custom documents, enabling it to provide answers to user queries based on the referenced information.

-  **Chat with SQL database** \
  Enable the chatbot to interact with a SQL database through simple, conversational commands.

## <img src="https://streamlit.io/images/brand/streamlit-mark-color.png" width="40" height="22"> Streamlit App
Created a multi-page streamlit app containing all sample chatbot use cases. \
You can access this app through this link: [langchain-chatbot.streamlit.app](https://langchain-chatbot.streamlit.app)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://langchain-chatbot.streamlit.app/)

## üñ•Ô∏è Running locally
```shell
# Run main streamlit app
$ streamlit run Home.py
```

## üíÅ Contributing
Planning to add more chatbot examples over time. PRs are welcome.

File: Home.py
import streamlit as st

st.set_page_config(
    page_title="Langchain Chatbot",
    page_icon='üí¨',
    layout='wide'
)

st.header("Chatbot Implementations with Langchain")
st.write("""
[![view source code ](https://img.shields.io/badge/GitHub%20Repository-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot)
[![linkedin ](https://img.shields.io/badge/Shashank%20Deshpande-blue?logo=linkedin&color=gray)](https://www.linkedin.com/in/shashank-deshpande/)
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Flangchain-chatbot.streamlit.app&label=Visitors&labelColor=%235d5d5d&countColor=%231e7ebf&style=flat)
""")
st.write("""
Langchain is a powerful framework designed to streamline the development of applications using Language Models (LLMs). It provides a comprehensive integration of various components, simplifying the process of assembling them to create robust applications.

Leveraging the power of Langchain, the creation of chatbots becomes effortless. Here are a few examples of chatbot implementations catering to different use cases:

- **Basic Chatbot**: Engage in interactive conversations with the LLM.
- **Context aware chatbot**: A chatbot that remembers previous conversations and provides responses accordingly.
- **Chatbot with Internet Access**: An internet-enabled chatbot capable of answering user queries about recent events.
- **Chat with your documents**: Empower the chatbot with the ability to access custom documents, enabling it to provide answers to user queries based on the referenced information.
- **Chat with SQL database**: Enable the chatbot to interact with a SQL database through simple, conversational commands.

To explore sample usage of each chatbot, please navigate to the corresponding chatbot section.
""")

File: streaming.py
from langchain_core.callbacks import BaseCallbackHandler

class StreamHandler(BaseCallbackHandler):
    
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.container.markdown(self.text)

File: LICENSE
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


File: requirements.txt
langchain==0.2.9
langchain_community==0.2.7
langchain_core==0.2.21
langchain_openai==0.1.17
langchain_text_splitters==0.2.2
openai==1.35.15
SQLAlchemy==2.0.31
streamlit==1.36.0
duckduckgo-search==6.2.1
pypdf==4.3.0
sentence-transformers==3.0.1
docarray==0.40.0


File: utils.py
import os
import openai
import streamlit as st
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama

#decorator
def enable_chat_history(func):
    if os.environ.get("OPENAI_API_KEY"):

        # to clear chat history after swtching chatbot
        current_page = func.__qualname__
        if "current_page" not in st.session_state:
            st.session_state["current_page"] = current_page
        if st.session_state["current_page"] != current_page:
            try:
                st.cache_resource.clear()
                del st.session_state["current_page"]
                del st.session_state["messages"]
            except:
                pass

        # to show chat history on ui
        if "messages" not in st.session_state:
            st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]
        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    def execute(*args, **kwargs):
        func(*args, **kwargs)
    return execute

def display_msg(msg, author):
    """Method to display message on the UI

    Args:
        msg (str): message to display
        author (str): author of the message -user/assistant
    """
    st.session_state.messages.append({"role": author, "content": msg})
    st.chat_message(author).write(msg)

def choose_custom_openai_key():
    openai_api_key = st.sidebar.text_input(
        label="OpenAI API Key",
        type="password",
        placeholder="sk-...",
        key="SELECTED_OPENAI_API_KEY"
        )
    if not openai_api_key:
        st.error("Please add your OpenAI API key to continue.")
        st.info("Obtain your key from this link: https://platform.openai.com/account/api-keys")
        st.stop()

    model = "gpt-4o-mini"
    try:
        client = openai.OpenAI(api_key=openai_api_key)
        available_models = [{"id": i.id, "created":datetime.fromtimestamp(i.created)} for i in client.models.list() if str(i.id).startswith("gpt")]
        available_models = sorted(available_models, key=lambda x: x["created"])
        available_models = [i["id"] for i in available_models]

        model = st.sidebar.selectbox(
            label="Model",
            options=available_models,
            key="SELECTED_OPENAI_MODEL"
        )
    except openai.AuthenticationError as e:
        st.error(e.body["message"])
        st.stop()
    except Exception as e:
        print(e)
        st.error("Something went wrong. Please try again later.")
        st.stop()
    return model, openai_api_key

def configure_llm():
    available_llms = ["gpt-4o-mini","llama3:8b","use your openai api key"]
    llm_opt = st.sidebar.radio(
        label="LLM",
        options=available_llms,
        key="SELECTED_LLM"
        )

    if llm_opt == "llama3:8b":
        llm = ChatOllama(model="llama3", base_url=st.secrets["OLLAMA_ENDPOINT"])
    elif llm_opt == "gpt-4o-mini":
        llm = ChatOpenAI(model_name=llm_opt, temperature=0, streaming=True, api_key=st.secrets["OPENAI_API_KEY"])
    else:
        model, openai_api_key = choose_custom_openai_key()
        llm = ChatOpenAI(model_name=model, temperature=0, streaming=True, api_key=openai_api_key)
    return llm

def sync_st_session():
    for k, v in st.session_state.items():
        st.session_state[k] = v

File: tools/scripts/project_file_scanner.py
import os
import fnmatch
import sys

def get_ignore_patterns(file_path):
    patterns = []
    if os.path.exists(file_path):
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.append(line)
    return patterns

def get_gitignore_patterns(base_dir):
    patterns = []
    gitignore_paths = [
        os.path.join(base_dir, '.gitignore'),
        os.path.join(base_dir, 'app', 'frontend', '.gitignore'),
        os.path.join(base_dir, 'ios', '.gitignore'),
        os.path.join(base_dir, 'android', '.gitignore')
    ]
    for gitignore_path in gitignore_paths:
        patterns.extend(get_ignore_patterns(gitignore_path))
    return patterns

def should_include(file_path, patterns):
    for pattern in patterns:
        if pattern.startswith('/'):
            if fnmatch.fnmatch(file_path, pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(file_path + '/', pattern):
                return False
        else:
            if fnmatch.fnmatch(file_path, pattern) or fnmatch.fnmatch(os.path.basename(file_path), pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(os.path.basename(file_path) + '/', pattern):
                return False
    return True

def collect_project_files(base_dir='.'):
    script_dir = os.path.abspath(base_dir)
    print(script_dir)
    utils_dir = os.path.join(script_dir, 'tools/data')
    print(utils_dir)
    output_dir = os.path.join(utils_dir, 'scanned_project_files')
    print(output_dir)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    overview_filename = os.path.join(output_dir, 'tree.txt')
    detailed_filename = os.path.join(output_dir, 'codes.txt')
    log_filename = os.path.join(output_dir, 'log.txt')
    additional_ignore_path = os.path.join(utils_dir, 'additional_ignore.txt')

    gitignore_patterns = get_gitignore_patterns(base_dir)
    additional_ignore_patterns = get_ignore_patterns(additional_ignore_path)
    patterns = list(set(gitignore_patterns + additional_ignore_patterns))

    open(overview_filename, 'w').close()
    open(detailed_filename, 'w').close()
    open(log_filename, 'w').close()

    with open(overview_filename, 'a', encoding='utf-8') as overview_file, \
         open(detailed_filename, 'a', encoding='utf-8') as detailed_file, \
         open(log_filename, 'a', encoding='utf-8') as logfile:
         
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, script_dir)
                
                if should_include(relative_path, patterns):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as infile:
                            detailed_file.write(f"File: {relative_path}\n")
                            detailed_file.write(infile.read())
                            detailed_file.write("\n\n")
                            logfile.write(f"Including file: {relative_path}\n")
                    except UnicodeDecodeError as e:
                        logfile.write(f"Could not read file (encoding issue) {file_path}: {e}\n")
                    except Exception as e:
                        logfile.write(f"Could not read file {file_path}: {e}\n")
                else:
                    logfile.write(f"Excluded by pattern: {relative_path}\n")
        
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            relative_path = os.path.relpath(root, script_dir)
            if should_include(relative_path, patterns):
                overview_file.write(f"Directory: {relative_path}\n")
                overview_file.write("Contains:\n")
                for dir in dirs:
                    overview_file.write(f"- {dir}\n")
                for file in files:
                    file_relative_path = os.path.relpath(os.path.join(root, file), script_dir)
                    if should_include(file_relative_path, patterns):
                        overview_file.write(f"- {file}\n")
                overview_file.write("\n")
            else:
                logfile.write(f"Excluded directory by pattern: {relative_path}\n")

if __name__ == "__main__":
    base_dir = sys.argv[1] if len(sys.argv) > 1 else '.'
    collect_project_files(base_dir)

File: tools/scripts/codes_by_folders.py


File: tools/data/scanned_project_files/tree.txt


File: .devcontainer/devcontainer.json
// For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:
// https://github.com/microsoft/vscode-dev-containers/tree/v0.209.6/containers/python-3
{
    "image": "mcr.microsoft.com/devcontainers/python:3.11-bullseye",
    "customizations": {
        "codespaces": {
          "openFiles": [
            "README.md",
            "Home.py"
          ]
        },
        "vscode": {
          "settings": {},
          "extensions": [
            "ms-python.python",
            "ms-python.vscode-pylance"
          ]
        }
      },
    "forwardPorts": [
        8501
    ],
    "postCreateCommand": "pip3 install --user -r requirements.txt",
    "postAttachCommand": {
        "server": "streamlit run Home.py --server.enableCORS false --server.enableXsrfProtection false"
    },
    "portsAttributes": {
        "8501": {
            "label": "Application",
            "onAutoForward": "openPreview"
        }
    },
    "remoteUser": "vscode"
}

File: assets/Chinook.db
File: pages/3_üåê_chatbot_with_internet_access.py
import utils
import streamlit as st

from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import Tool

st.set_page_config(page_title="ChatWeb", page_icon="üåê")
st.header('Chatbot with Internet Access')
st.write('Equipped with internet access, enables users to ask questions about recent events')
st.write('[![view source code ](https://img.shields.io/badge/view_source_code-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/3_%F0%9F%8C%90_chatbot_with_internet_access.py)')

class InternetChatbot:

    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()

    @st.cache_resource(show_spinner='Connecting..')
    def setup_agent(_self):
        # Define tool
        ddg_search = DuckDuckGoSearchRun()
        tools = [
            Tool(
                name="DuckDuckGoSearch",
                func=ddg_search.run,
                description="Useful for when you need to answer questions about current events. You should ask targeted questions",
            )
        ]

        # Get the prompt - can modify this
        prompt = hub.pull("hwchase17/react-chat")

        # Setup LLM and Agent
        memory = ConversationBufferMemory(memory_key="chat_history")
        agent = create_react_agent(_self.llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)
        return agent_executor, memory

    @utils.enable_chat_history
    def main(self):
        agent_executor, memory = self.setup_agent()
        user_query = st.chat_input(placeholder="Ask me anything!")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamlitCallbackHandler(st.container())
                result = agent_executor.invoke(
                    {"input": user_query, "chat_history": memory.chat_memory.messages},
                    {"callbacks": [st_cb]}
                )
                response = result["output"]
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.write(response)

if __name__ == "__main__":
    obj = InternetChatbot()
    obj.main()

File: pages/4_üìÑ_chat_with_your_documents.py
import os
import utils
import streamlit as st
from streaming import StreamHandler

from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import DocArrayInMemorySearch
from langchain_text_splitters import RecursiveCharacterTextSplitter

st.set_page_config(page_title="ChatPDF", page_icon="üìÑ")
st.header('Chat with your documents (Basic RAG)')
st.write('Has access to custom documents and can respond to user queries by referring to the content within those documents')
st.write('[![view source code ](https://img.shields.io/badge/view_source_code-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/4_%F0%9F%93%84_chat_with_your_documents.py)')

class CustomDataChatbot:

    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()

    def save_file(self, file):
        folder = 'tmp'
        if not os.path.exists(folder):
            os.makedirs(folder)
        
        file_path = f'./{folder}/{file.name}'
        with open(file_path, 'wb') as f:
            f.write(file.getvalue())
        return file_path

    @st.spinner('Analyzing documents..')
    def setup_qa_chain(self, uploaded_files):
        # Load documents
        docs = []
        for file in uploaded_files:
            file_path = self.save_file(file)
            loader = PyPDFLoader(file_path)
            docs.extend(loader.load())
        
        # Split documents
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(docs)

        # Create embeddings and store in vectordb
        embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")
        vectordb = DocArrayInMemorySearch.from_documents(splits, embeddings)

        # Define retriever
        retriever = vectordb.as_retriever(
            search_type='mmr',
            search_kwargs={'k':2, 'fetch_k':4}
        )

        # Setup memory for contextual conversation        
        memory = ConversationBufferMemory(
            memory_key='chat_history',
            output_key='answer',
            return_messages=True
        )

        # Setup LLM and QA chain
        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=retriever,
            memory=memory,
            return_source_documents=True,
            verbose=True
        )
        return qa_chain

    @utils.enable_chat_history
    def main(self):

        # User Inputs
        uploaded_files = st.sidebar.file_uploader(label='Upload PDF files', type=['pdf'], accept_multiple_files=True)
        if not uploaded_files:
            st.error("Please upload PDF documents to continue!")
            st.stop()

        user_query = st.chat_input(placeholder="Ask me anything!")

        if uploaded_files and user_query:
            qa_chain = self.setup_qa_chain(uploaded_files)

            utils.display_msg(user_query, 'user')

            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                result = qa_chain.invoke(
                    {"question":user_query},
                    {"callbacks": [st_cb]}
                )
                response = result["answer"]
                st.session_state.messages.append({"role": "assistant", "content": response})

                # to show references
                for idx, doc in enumerate(result['source_documents'],1):
                    filename = os.path.basename(doc.metadata['source'])
                    page_num = doc.metadata['page']
                    ref_title = f":blue[Reference {idx}: *{filename} - page.{page_num}*]"
                    with st.popover(ref_title):
                        st.caption(doc.page_content)

if __name__ == "__main__":
    obj = CustomDataChatbot()
    obj.main()

File: pages/5_üõ¢_chat_with_sql_db.py
import utils
import sqlite3
import streamlit as st
from pathlib import Path
from sqlalchemy import create_engine

from langchain_openai import ChatOpenAI
from langchain_community.agent_toolkits import create_sql_agent
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.utilities.sql_database import SQLDatabase

st.set_page_config(page_title="ChatSQL", page_icon="üõ¢")
st.header('Chat with SQL database')
st.write('Enable the chatbot to interact with a SQL database through simple, conversational commands.')
st.write('[![view source code ](https://img.shields.io/badge/view_source_code-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/5_%F0%9F%9B%A2_chat_with_sql_db.py)')

class SqlChatbot:

    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
    
    def setup_db(_self, db_uri):
        if db_uri == 'USE_SAMPLE_DB':
            db_filepath = (Path(__file__).parent.parent / "assets/Chinook.db").absolute()
            db_uri = f"sqlite:////{db_filepath}"
            creator = lambda: sqlite3.connect(f"file:{db_filepath}?mode=ro", uri=True)
            db = SQLDatabase(create_engine("sqlite:///", creator=creator))
        else:
            db = SQLDatabase.from_uri(database_uri=db_uri)
        
        with st.sidebar.expander('Database tables', expanded=True):
            st.info('\n- '+'\n- '.join(db.get_usable_table_names()))
        return db
    
    def setup_sql_agent(_self, db):
        agent = create_sql_agent(
            llm=_self.llm,
            db=db,
            top_k=10,
            verbose=True,
            agent_type="openai-tools",
            handle_parsing_errors=True,
            handle_sql_errors=True
        )
        return agent

    @utils.enable_chat_history
    def main(self):

        # User inputs
        radio_opt = ['Use sample db - Chinook.db','Connect to your SQL db']
        selected_opt = st.sidebar.radio(
            label='Choose suitable option',
            options=radio_opt
        )
        if radio_opt.index(selected_opt) == 1:
            with st.sidebar.popover(':orange[‚ö†Ô∏è Security note]', use_container_width=True):
                warning = "Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. Make sure that your database connection permissions are always scoped as narrowly as possible for your chain/agent's needs.\n\nFor more on general security best practices - [read this](https://python.langchain.com/docs/security)."
                st.warning(warning)
            db_uri = st.sidebar.text_input(
                label='Database URI',
                placeholder='mysql://user:pass@hostname:port/db'
            )
        else:
            db_uri = 'USE_SAMPLE_DB'
        
        if not db_uri:
            st.error("Please enter database URI to continue!")
            st.stop()
        
        db = self.setup_db(db_uri)
        agent = self.setup_sql_agent(db)

        user_query = st.chat_input(placeholder="Ask me anything!")

        if user_query:
            st.session_state.messages.append({"role": "user", "content": user_query})
            st.chat_message("user").write(user_query)

            with st.chat_message("assistant"):
                st_cb = StreamlitCallbackHandler(st.container())
                result = agent.invoke(
                    {"input": user_query},
                    {"callbacks": [st_cb]}
                )
                response = result["output"]
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.write(response)

if __name__ == "__main__":
    obj = SqlChatbot()
    obj.main()

File: pages/2_‚≠ê_context_aware_chatbot.py
import utils
import streamlit as st
from streaming import StreamHandler

from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

st.set_page_config(page_title="Context aware chatbot", page_icon="‚≠ê")
st.header('Context aware chatbot')
st.write('Enhancing Chatbot Interactions through Context Awareness')
st.write('[![view source code ](https://img.shields.io/badge/view_source_code-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py)')

class ContextChatbot:

    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
    
    @st.cache_resource
    def setup_chain(_self):
        memory = ConversationBufferMemory()
        chain = ConversationChain(llm=_self.llm, memory=memory, verbose=True)
        return chain
    
    @utils.enable_chat_history
    def main(self):
        chain = self.setup_chain()
        user_query = st.chat_input(placeholder="Ask me anything!")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                result = chain.invoke(
                    {"input":user_query},
                    {"callbacks": [st_cb]}
                )
                response = result["response"]
                st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    obj = ContextChatbot()
    obj.main()


File: pages/1_üí¨_basic_chatbot.py
import utils
import streamlit as st
from streaming import StreamHandler

from langchain.chains import ConversationChain

st.set_page_config(page_title="Chatbot", page_icon="üí¨")
st.header('Basic Chatbot')
st.write('Allows users to interact with the LLM')
st.write('[![view source code ](https://img.shields.io/badge/view_source_code-gray?logo=github)](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/1_%F0%9F%92%AC_basic_chatbot.py)')

class BasicChatbot:

    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
    
    def setup_chain(self):
        chain = ConversationChain(llm=self.llm, verbose=True)
        return chain
    
    @utils.enable_chat_history
    def main(self):
        chain = self.setup_chain()
        user_query = st.chat_input(placeholder="Ask me anything!")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                result = chain.invoke(
                    {"input":user_query},
                    {"callbacks": [st_cb]}
                )
                response = result["response"]
                st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    obj = BasicChatbot()
    obj.main()

