File: .gitignore
## Frontend
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.js

# testing
/coverage

# next.js
*.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local
.env.dev
.env.prod
.env.test

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

.env.local
.env.development.local
.env.test.local
.env.production.local


#amplify-do-not-edit-begin
amplify/\#current-cloud-backend
amplify/.config/local-*
amplify/logs
amplify/mock-data
amplify/mock-api-resources
amplify/backend/amplify-meta.json
amplify/backend/.temp
node_modules/
aws-exports.js
awsconfiguration.json
amplifyconfiguration.json
amplifyconfiguration.dart
amplify-build-config.json
amplify-gradle-config.json
amplifytools.xcconfig
.secret-*
**.sample
#amplify-do-not-edit-end

#intellij env
.idea/

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

/creds
/logs
/projects
/ai/knowledge
*.sqlite
*_cache*
/scripts/*.txt
utils/project_info/project_log.txt
docs_gen/**/*.txt



File: README.md
# Chatbot Implementations with Langchain + Streamlit

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/shashankdeshpande/langchain-chatbot?quickstart=1)

Langchain is a powerful framework designed to streamline the development of applications using Language Models (LLMs). \
It provides a comprehensive integration of various components, simplifying the process of assembling them to create robust applications.

## 💬 Sample chatbot use cases
Here are a few examples of chatbot implementations using Langchain and Streamlit:
-  **Basic Chatbot** \
  Engage in interactive conversations with the LLM.

- **Context aware chatbot** \
  A chatbot that remembers previous conversations and provides responses accordingly.

-  **Chatbot with Internet Access** \
  An internet-enabled chatbot capable of answering user queries about recent events.

-  **Chat with your documents** \
  Empower the chatbot with the ability to access custom documents, enabling it to provide answers to user queries based on the referenced information.

-  **Chat with SQL database** \
  Enable the chatbot to interact with a SQL database through simple, conversational commands.

## <img src="https://streamlit.io/images/brand/streamlit-mark-color.png" width="40" height="22"> Streamlit App
Created a multi-page streamlit app containing all sample chatbot use cases. \
You can access this app through this link: [langchain-chatbot.streamlit.app](https://langchain-chatbot.streamlit.app)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://langchain-chatbot.streamlit.app/)

## 🖥️ Running locally
```shell
# Run main streamlit app
$ streamlit run Home.py
```

## 💁 Contributing
Planning to add more chatbot examples over time. PRs are welcome.

File: main.py
import streamlit as st
from loguru import logger

st.set_page_config(
    page_title="Langchain 챗봇",
    page_icon='💬',
    layout='wide'
)

logger.info("메인 페이지 로드됨")

st.header("Langchain을 활용한 챗봇 구현")

st.write("""
Langchain은 언어 모델(LLMs)을 사용하는 애플리케이션 개발을 간소화하기 위해 설계된 강력한 프레임워크입니다. 
다양한 구성 요소를 포괄적으로 통합하여 강력한 애플리케이션을 만드는 과정을 단순화합니다.

Langchain의 능력을 활용하면 챗봇 생성이 쉬워집니다. 다음은 다양한 사용 사례에 맞춘 챗봇 구현의 예시들입니다:

- **기본 챗봇**: LLM과 대화형 상호작용을 할 수 있습니다.
- **컨텍스트 인식 챗봇**: 이전 대화를 기억하고 그에 따라 응답을 제공하는 챗봇입니다.
- **인터넷 접근 가능 챗봇**: 최근 사건에 대한 사용자 질문에 답변할 수 있는 인터넷 지원 챗봇입니다.
- **문서 기반 챗봇**: 사용자 정의 문서에 접근할 수 있는 능력을 갖춘 챗봇으로, 참조된 정보를 바탕으로 사용자 질문에 답변할 수 있습니다.
- **SQL 데이터베이스 챗봇**: 간단한 대화형 명령을 통해 SQL 데이터베이스와 상호작용할 수 있는 챗봇입니다.

각 챗봇의 사용 예시를 탐색하려면 해당 챗봇 섹션으로 이동하세요.
""")

# 버전 정보 표시
st.sidebar.text("버전: 1.0.0")

# 피드백 섹션
st.sidebar.text_input("피드백", placeholder="여기에 피드백을 입력하세요")
if st.sidebar.button("피드백 제출"):
    # 피드백 처리 로직을 여기에 추가할 수 있습니다.
    logger.info("사용자가 피드백을 제출함")
    st.sidebar.success("피드백을 주셔서 감사합니다!")

logger.info("메인 페이지 렌더링 완료")

File: streaming.py
from langchain_core.callbacks import BaseCallbackHandler

class StreamHandler(BaseCallbackHandler):
    
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.container.markdown(self.text)

File: LICENSE
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


File: requirements.txt
langchain==0.2.9
langchain_community==0.2.7
langchain_core==0.2.21
langchain_openai==0.1.17
langchain_text_splitters==0.2.2
openai==1.35.15
SQLAlchemy==2.0.31
streamlit==1.36.0
duckduckgo-search==6.2.1
pypdf==4.3.0
sentence-transformers==3.0.1
docarray==0.40.0


File: utils.py
import os
import openai
import streamlit as st
from datetime import datetime
from loguru import logger
from config.settings import settings
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama

def setup_logging():
    logger.add("logs/app.log", rotation="500 MB", level="INFO")
    if settings.OPENAI_API_KEY:
        logger.info(f"OPENAI_API_KEY loaded: {settings.OPENAI_API_KEY.get_secret_value()[:5]}...{settings.OPENAI_API_KEY.get_secret_value()[-5:]}")
    else:
        logger.error("OPENAI_API_KEY is not set in the environment variables.")

setup_logging()

def enable_chat_history(func):
    if settings.OPENAI_API_KEY:
        current_page = func.__qualname__
        if "current_page" not in st.session_state:
            st.session_state["current_page"] = current_page
        if st.session_state["current_page"] != current_page:
            try:
                st.cache_resource.clear()
                del st.session_state["current_page"]
                del st.session_state["messages"]
            except KeyError:
                pass

        if "messages" not in st.session_state:
            st.session_state["messages"] = [{"role": "assistant", "content": "무엇을 도와드릴까요?"}]
        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    def execute(*args, **kwargs):
        func(*args, **kwargs)
    return execute

def display_msg(msg, author):
    st.session_state.messages.append({"role": author, "content": msg})
    st.chat_message(author).write(msg)

def get_openai_model_list(api_key):
    try:
        client = openai.OpenAI(api_key=api_key)
        models = client.models.list()
        gpt_models = [{"id": m.id, "created": datetime.fromtimestamp(m.created)} for m in models if m.id.startswith("gpt")]
        return sorted(gpt_models, key=lambda x: x["created"], reverse=True)
    except openai.AuthenticationError as e:
        logger.error(f"OpenAI 인증 오류: {str(e)}")
        st.error("OpenAI API 키가 유효하지 않습니다.")
        st.stop()
    except Exception as e:
        logger.error(f"OpenAI 모델 목록 조회 중 오류 발생: {str(e)}")
        st.error("모델 목록을 가져오는 중 오류가 발생했습니다. 나중에 다시 시도해주세요.")
        st.stop()

def configure_llm():
    available_llms = [settings.DEFAULT_MODEL, "llama3:8b", "OpenAI API 키 사용"]
    llm_opt = st.sidebar.radio("LLM 선택", options=available_llms, key="SELECTED_LLM")

    if llm_opt == "llama3:8b":
        return ChatOllama(model="llama3", base_url=settings.OLLAMA_ENDPOINT)
    elif llm_opt == settings.DEFAULT_MODEL:
        return ChatOpenAI(model_name=llm_opt, temperature=0, streaming=True, api_key=settings.OPENAI_API_KEY.get_secret_value())
    else:
        openai_api_key = st.sidebar.text_input("OpenAI API 키", type="password", placeholder="sk-...", key="CUSTOM_OPENAI_API_KEY")
        if not openai_api_key:
            st.error("계속하려면 OpenAI API 키를 입력해주세요.")
            st.info("API 키는 다음 링크에서 얻을 수 있습니다: https://platform.openai.com/account/api-keys")
            st.stop()

        available_models = get_openai_model_list(openai_api_key)
        model = st.sidebar.selectbox("모델 선택", options=[m["id"] for m in available_models], key="SELECTED_OPENAI_MODEL")
        return ChatOpenAI(model_name=model, temperature=0, streaming=True, api_key=openai_api_key)

def sync_st_session():
    for k, v in st.session_state.items():
        st.session_state[k] = v

File: tools/scripts/project_file_scanner.py
import os
import fnmatch
import sys

def get_ignore_patterns(file_path):
    patterns = []
    if os.path.exists(file_path):
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.append(line)
    return patterns

def get_gitignore_patterns(base_dir):
    patterns = []
    gitignore_paths = [
        os.path.join(base_dir, '.gitignore'),
        os.path.join(base_dir, 'app', 'frontend', '.gitignore'),
        os.path.join(base_dir, 'ios', '.gitignore'),
        os.path.join(base_dir, 'android', '.gitignore')
    ]
    for gitignore_path in gitignore_paths:
        patterns.extend(get_ignore_patterns(gitignore_path))
    return patterns

def should_include(file_path, patterns):
    for pattern in patterns:
        if pattern.startswith('/'):
            if fnmatch.fnmatch(file_path, pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(file_path + '/', pattern):
                return False
        else:
            if fnmatch.fnmatch(file_path, pattern) or fnmatch.fnmatch(os.path.basename(file_path), pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(os.path.basename(file_path) + '/', pattern):
                return False
    return True

def collect_project_files(base_dir='.'):
    script_dir = os.path.abspath(base_dir)
    print(script_dir)
    utils_dir = os.path.join(script_dir, 'tools/data')
    print(utils_dir)
    output_dir = os.path.join(utils_dir, 'scanned_project_files')
    print(output_dir)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    overview_filename = os.path.join(output_dir, 'tree.txt')
    detailed_filename = os.path.join(output_dir, 'codes.txt')
    log_filename = os.path.join(output_dir, 'log.txt')
    additional_ignore_path = os.path.join(utils_dir, 'additional_ignore.txt')

    gitignore_patterns = get_gitignore_patterns(base_dir)
    additional_ignore_patterns = get_ignore_patterns(additional_ignore_path)
    patterns = list(set(gitignore_patterns + additional_ignore_patterns))

    open(overview_filename, 'w').close()
    open(detailed_filename, 'w').close()
    open(log_filename, 'w').close()

    with open(overview_filename, 'a', encoding='utf-8') as overview_file, \
         open(detailed_filename, 'a', encoding='utf-8') as detailed_file, \
         open(log_filename, 'a', encoding='utf-8') as logfile:
         
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, script_dir)
                
                if should_include(relative_path, patterns):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as infile:
                            detailed_file.write(f"File: {relative_path}\n")
                            detailed_file.write(infile.read())
                            detailed_file.write("\n\n")
                            logfile.write(f"Including file: {relative_path}\n")
                    except UnicodeDecodeError as e:
                        logfile.write(f"Could not read file (encoding issue) {file_path}: {e}\n")
                    except Exception as e:
                        logfile.write(f"Could not read file {file_path}: {e}\n")
                else:
                    logfile.write(f"Excluded by pattern: {relative_path}\n")
        
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            relative_path = os.path.relpath(root, script_dir)
            if should_include(relative_path, patterns):
                overview_file.write(f"Directory: {relative_path}\n")
                overview_file.write("Contains:\n")
                for dir in dirs:
                    overview_file.write(f"- {dir}\n")
                for file in files:
                    file_relative_path = os.path.relpath(os.path.join(root, file), script_dir)
                    if should_include(file_relative_path, patterns):
                        overview_file.write(f"- {file}\n")
                overview_file.write("\n")
            else:
                logfile.write(f"Excluded directory by pattern: {relative_path}\n")

if __name__ == "__main__":
    base_dir = sys.argv[1] if len(sys.argv) > 1 else '.'
    collect_project_files(base_dir)

File: tools/scripts/codes_by_folders.py
import os
import fnmatch
import shutil
from pathlib import Path

def get_gitignore_patterns(base_dir):
    gitignore_path = Path(base_dir) / '.gitignore'
    patterns = []
    if gitignore_path.exists():
        with open(gitignore_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    if not line.startswith('/'):
                        line = f'**/{line}'
                    patterns.append(line)
    return patterns

def is_ignored(path, base_path, patterns):
    rel_path = path.relative_to(base_path)
    for pattern in patterns:
        if fnmatch.fnmatch(str(rel_path), pattern) or fnmatch.fnmatch(str(rel_path) + '/', pattern):
            return True
    return False

def is_code_file(file_path):
    code_extensions = ['.py', '.dart', '.js', '.ts']  # 필요한 파일 확장자를 추가하세요
    return file_path.suffix in code_extensions

def combine_code_files(source_dir, dest_dir):
    source_path = Path(source_dir).resolve()
    dest_path = Path(dest_dir).resolve()
    
    if not source_path.exists():
        raise FileNotFoundError(f"Source directory '{source_path}' does not exist.")
    
    dest_path.mkdir(parents=True, exist_ok=True)
    
    ignore_patterns = get_gitignore_patterns(source_path)
    
    all_included_files = []

    # 먼저 root 폴더의 주요 파일들을 처리합니다
    for file in source_path.glob('*'):
        if file.is_file() and is_code_file(file) and not is_ignored(file, source_path, ignore_patterns):
            shutil.copy2(file, dest_path)
            all_included_files.append(file.name)

    for root, dirs, files in os.walk(source_path):
        rel_path = Path(root).relative_to(source_path)
        current_path = source_path / rel_path
        
        dirs[:] = [d for d in dirs if not is_ignored(current_path / d, source_path, ignore_patterns)]
        
        if not is_ignored(current_path, source_path, ignore_patterns):
            (dest_path / rel_path).mkdir(parents=True, exist_ok=True)
            
            combined_code = f"Combined code for {rel_path}\n\n"
            included_files = []
            
            for file in files:
                file_path = current_path / file
                if is_code_file(file_path) and not is_ignored(file_path, source_path, ignore_patterns):
                    rel_file_path = file_path.relative_to(source_path)
                    included_files.append(str(rel_file_path))
                    all_included_files.append(str(rel_file_path))
                    combined_code += f"File: {rel_file_path}\n"
                    with open(file_path, 'r', encoding='utf-8') as f:
                        combined_code += f.read()
                    combined_code += "\n\n"
            
            # Write combined code
            with open(dest_path / rel_path / 'combined_code.txt', 'w', encoding='utf-8') as f:
                f.write(combined_code)
            
            # Write list of included files for this directory
            with open(dest_path / rel_path / 'included_files.txt', 'w', encoding='utf-8') as f:
                for file in included_files:
                    f.write(f"{file}\n")

    # Write list of all included files in the root directory
    with open(dest_path / 'all_included_files.txt', 'w', encoding='utf-8') as f:
        for file in sorted(all_included_files):
            f.write(f"{file}\n")

    print(f"Directory structure and combined code created in '{dest_path}'")

# 실행
if __name__ == "__main__":
    source_directory = "."  # 현재 디렉토리를 root로 설정
    destination_directory = "docs_gen"  # docs_gen 폴더 경로
    
    combine_code_files(source_directory, destination_directory)

File: tools/scripts/db_scanner.py
import os
import json
from datetime import datetime, timezone
from loguru import logger
from typing import Optional, Dict, Any
from dotenv import load_dotenv
from sqlalchemy import create_engine, inspect

# .env 파일에서 환경 변수 로드
load_dotenv('.env.dev')

# 환경 변수에서 설정 가져오기
class Settings:
    postgres_user = os.getenv("POSTGRES_USER")
    postgres_password = os.getenv("POSTGRES_PASSWORD")
    postgres_host = os.getenv("POSTGRES_HOST")
    postgres_port = os.getenv("POSTGRES_PORT")
    postgres_dbname = os.getenv("POSTGRES_DBNAME")

settings = Settings()

# 데이터베이스 연결 문자열 생성
DATABASE_URL = f"postgresql://{settings.postgres_user}:{settings.postgres_password}@{settings.postgres_host}:{settings.postgres_port}/{settings.postgres_dbname}"

def fetch_db_info(engine):
    db_info = {}
    inspector = inspect(engine)
    
    for schema in inspector.get_schema_names():
        if schema not in ['information_schema', 'pg_catalog']:
            db_info[schema] = {}
            for table_name in inspector.get_table_names(schema=schema):
                db_info[schema][table_name] = {
                    "columns": [],
                    "foreign_keys": [],
                    "primary_key": []
                }
                
                # 컬럼 정보
                for column in inspector.get_columns(table_name, schema=schema):
                    db_info[schema][table_name]["columns"].append({
                        "column_name": column['name'],
                        "data_type": str(column['type'])
                    })
                
                # 외래 키 정보
                for fk in inspector.get_foreign_keys(table_name, schema=schema):
                    db_info[schema][table_name]["foreign_keys"].append({
                        "constrained_columns": fk['constrained_columns'],
                        "referred_schema": fk['referred_schema'],
                        "referred_table": fk['referred_table'],
                        "referred_columns": fk['referred_columns']
                    })
                
                # 기본 키 정보
                pk = inspector.get_pk_constraint(table_name, schema=schema)
                if pk and 'constrained_columns' in pk:
                    db_info[schema][table_name]["primary_key"] = pk['constrained_columns']
    
    return db_info

def save_to_json(data, filename):
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def scan_and_save_db_info(engine):
    db_info = fetch_db_info(engine)
    save_to_json(db_info, 'tools/data/configs/database_schema.json')
    return db_info

def main():
    logger.info("Starting database schema scan")
    
    try:
        engine = create_engine(DATABASE_URL)
        db_info = scan_and_save_db_info(engine)
        logger.info(f"Database schema saved to database_schema.json")
        logger.info(f"Scanned {len(db_info)} schemas")
        for schema, tables in db_info.items():
            logger.info(f"Schema '{schema}' contains {len(tables)} tables")
    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
    
    logger.info("Database schema scan completed")

if __name__ == "__main__":
    main()

File: tools/data/scanned_project_files/log.txt


File: tools/data/scanned_project_files/codes.txt
File: .gitignore
## Frontend
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.js

# testing
/coverage

# next.js
*.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local
.env.dev
.env.prod
.env.test

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

.env.local
.env.development.local
.env.test.local
.env.production.local


#amplify-do-not-edit-begin
amplify/\#current-cloud-backend
amplify/.config/local-*
amplify/logs
amplify/mock-data
amplify/mock-api-resources
amplify/backend/amplify-meta.json
amplify/backend/.temp
node_modules/
aws-exports.js
awsconfiguration.json
amplifyconfiguration.json
amplifyconfiguration.dart
amplify-build-config.json
amplify-gradle-config.json
amplifytools.xcconfig
.secret-*
**.sample
#amplify-do-not-edit-end

#intellij env
.idea/

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

/creds
/logs
/projects
/ai/knowledge
*.sqlite
*_cache*
/scripts/*.txt
utils/project_info/project_log.txt
docs_gen/**/*.txt



File: README.md
# Chatbot Implementations with Langchain + Streamlit

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/shashankdeshpande/langchain-chatbot?quickstart=1)

Langchain is a powerful framework designed to streamline the development of applications using Language Models (LLMs). \
It provides a comprehensive integration of various components, simplifying the process of assembling them to create robust applications.

## 💬 Sample chatbot use cases
Here are a few examples of chatbot implementations using Langchain and Streamlit:
-  **Basic Chatbot** \
  Engage in interactive conversations with the LLM.

- **Context aware chatbot** \
  A chatbot that remembers previous conversations and provides responses accordingly.

-  **Chatbot with Internet Access** \
  An internet-enabled chatbot capable of answering user queries about recent events.

-  **Chat with your documents** \
  Empower the chatbot with the ability to access custom documents, enabling it to provide answers to user queries based on the referenced information.

-  **Chat with SQL database** \
  Enable the chatbot to interact with a SQL database through simple, conversational commands.

## <img src="https://streamlit.io/images/brand/streamlit-mark-color.png" width="40" height="22"> Streamlit App
Created a multi-page streamlit app containing all sample chatbot use cases. \
You can access this app through this link: [langchain-chatbot.streamlit.app](https://langchain-chatbot.streamlit.app)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://langchain-chatbot.streamlit.app/)

## 🖥️ Running locally
```shell
# Run main streamlit app
$ streamlit run Home.py
```

## 💁 Contributing
Planning to add more chatbot examples over time. PRs are welcome.

File: main.py
import streamlit as st
from loguru import logger

st.set_page_config(
    page_title="Langchain 챗봇",
    page_icon='💬',
    layout='wide'
)

logger.info("메인 페이지 로드됨")

st.header("Langchain을 활용한 챗봇 구현")

st.write("""
Langchain은 언어 모델(LLMs)을 사용하는 애플리케이션 개발을 간소화하기 위해 설계된 강력한 프레임워크입니다. 
다양한 구성 요소를 포괄적으로 통합하여 강력한 애플리케이션을 만드는 과정을 단순화합니다.

Langchain의 능력을 활용하면 챗봇 생성이 쉬워집니다. 다음은 다양한 사용 사례에 맞춘 챗봇 구현의 예시들입니다:

- **기본 챗봇**: LLM과 대화형 상호작용을 할 수 있습니다.
- **컨텍스트 인식 챗봇**: 이전 대화를 기억하고 그에 따라 응답을 제공하는 챗봇입니다.
- **인터넷 접근 가능 챗봇**: 최근 사건에 대한 사용자 질문에 답변할 수 있는 인터넷 지원 챗봇입니다.
- **문서 기반 챗봇**: 사용자 정의 문서에 접근할 수 있는 능력을 갖춘 챗봇으로, 참조된 정보를 바탕으로 사용자 질문에 답변할 수 있습니다.
- **SQL 데이터베이스 챗봇**: 간단한 대화형 명령을 통해 SQL 데이터베이스와 상호작용할 수 있는 챗봇입니다.

각 챗봇의 사용 예시를 탐색하려면 해당 챗봇 섹션으로 이동하세요.
""")

# 버전 정보 표시
st.sidebar.text("버전: 1.0.0")

# 피드백 섹션
st.sidebar.text_input("피드백", placeholder="여기에 피드백을 입력하세요")
if st.sidebar.button("피드백 제출"):
    # 피드백 처리 로직을 여기에 추가할 수 있습니다.
    logger.info("사용자가 피드백을 제출함")
    st.sidebar.success("피드백을 주셔서 감사합니다!")

logger.info("메인 페이지 렌더링 완료")

File: streaming.py
from langchain_core.callbacks import BaseCallbackHandler

class StreamHandler(BaseCallbackHandler):
    
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.container.markdown(self.text)

File: LICENSE
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


File: requirements.txt
langchain==0.2.9
langchain_community==0.2.7
langchain_core==0.2.21
langchain_openai==0.1.17
langchain_text_splitters==0.2.2
openai==1.35.15
SQLAlchemy==2.0.31
streamlit==1.36.0
duckduckgo-search==6.2.1
pypdf==4.3.0
sentence-transformers==3.0.1
docarray==0.40.0


File: utils.py
import os
import openai
import streamlit as st
from datetime import datetime
from loguru import logger
from config.settings import settings
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama

def setup_logging():
    logger.add("logs/app.log", rotation="500 MB", level="INFO")
    if settings.OPENAI_API_KEY:
        logger.info(f"OPENAI_API_KEY loaded: {settings.OPENAI_API_KEY.get_secret_value()[:5]}...{settings.OPENAI_API_KEY.get_secret_value()[-5:]}")
    else:
        logger.error("OPENAI_API_KEY is not set in the environment variables.")

setup_logging()

def enable_chat_history(func):
    if settings.OPENAI_API_KEY:
        current_page = func.__qualname__
        if "current_page" not in st.session_state:
            st.session_state["current_page"] = current_page
        if st.session_state["current_page"] != current_page:
            try:
                st.cache_resource.clear()
                del st.session_state["current_page"]
                del st.session_state["messages"]
            except KeyError:
                pass

        if "messages" not in st.session_state:
            st.session_state["messages"] = [{"role": "assistant", "content": "무엇을 도와드릴까요?"}]
        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    def execute(*args, **kwargs):
        func(*args, **kwargs)
    return execute

def display_msg(msg, author):
    st.session_state.messages.append({"role": author, "content": msg})
    st.chat_message(author).write(msg)

def get_openai_model_list(api_key):
    try:
        client = openai.OpenAI(api_key=api_key)
        models = client.models.list()
        gpt_models = [{"id": m.id, "created": datetime.fromtimestamp(m.created)} for m in models if m.id.startswith("gpt")]
        return sorted(gpt_models, key=lambda x: x["created"], reverse=True)
    except openai.AuthenticationError as e:
        logger.error(f"OpenAI 인증 오류: {str(e)}")
        st.error("OpenAI API 키가 유효하지 않습니다.")
        st.stop()
    except Exception as e:
        logger.error(f"OpenAI 모델 목록 조회 중 오류 발생: {str(e)}")
        st.error("모델 목록을 가져오는 중 오류가 발생했습니다. 나중에 다시 시도해주세요.")
        st.stop()

def configure_llm():
    available_llms = [settings.DEFAULT_MODEL, "llama3:8b", "OpenAI API 키 사용"]
    llm_opt = st.sidebar.radio("LLM 선택", options=available_llms, key="SELECTED_LLM")

    if llm_opt == "llama3:8b":
        return ChatOllama(model="llama3", base_url=settings.OLLAMA_ENDPOINT)
    elif llm_opt == settings.DEFAULT_MODEL:
        return ChatOpenAI(model_name=llm_opt, temperature=0, streaming=True, api_key=settings.OPENAI_API_KEY.get_secret_value())
    else:
        openai_api_key = st.sidebar.text_input("OpenAI API 키", type="password", placeholder="sk-...", key="CUSTOM_OPENAI_API_KEY")
        if not openai_api_key:
            st.error("계속하려면 OpenAI API 키를 입력해주세요.")
            st.info("API 키는 다음 링크에서 얻을 수 있습니다: https://platform.openai.com/account/api-keys")
            st.stop()

        available_models = get_openai_model_list(openai_api_key)
        model = st.sidebar.selectbox("모델 선택", options=[m["id"] for m in available_models], key="SELECTED_OPENAI_MODEL")
        return ChatOpenAI(model_name=model, temperature=0, streaming=True, api_key=openai_api_key)

def sync_st_session():
    for k, v in st.session_state.items():
        st.session_state[k] = v

File: tools/scripts/project_file_scanner.py
import os
import fnmatch
import sys

def get_ignore_patterns(file_path):
    patterns = []
    if os.path.exists(file_path):
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.append(line)
    return patterns

def get_gitignore_patterns(base_dir):
    patterns = []
    gitignore_paths = [
        os.path.join(base_dir, '.gitignore'),
        os.path.join(base_dir, 'app', 'frontend', '.gitignore'),
        os.path.join(base_dir, 'ios', '.gitignore'),
        os.path.join(base_dir, 'android', '.gitignore')
    ]
    for gitignore_path in gitignore_paths:
        patterns.extend(get_ignore_patterns(gitignore_path))
    return patterns

def should_include(file_path, patterns):
    for pattern in patterns:
        if pattern.startswith('/'):
            if fnmatch.fnmatch(file_path, pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(file_path + '/', pattern):
                return False
        else:
            if fnmatch.fnmatch(file_path, pattern) or fnmatch.fnmatch(os.path.basename(file_path), pattern):
                return False
            if os.path.isdir(file_path) and fnmatch.fnmatch(os.path.basename(file_path) + '/', pattern):
                return False
    return True

def collect_project_files(base_dir='.'):
    script_dir = os.path.abspath(base_dir)
    print(script_dir)
    utils_dir = os.path.join(script_dir, 'tools/data')
    print(utils_dir)
    output_dir = os.path.join(utils_dir, 'scanned_project_files')
    print(output_dir)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    overview_filename = os.path.join(output_dir, 'tree.txt')
    detailed_filename = os.path.join(output_dir, 'codes.txt')
    log_filename = os.path.join(output_dir, 'log.txt')
    additional_ignore_path = os.path.join(utils_dir, 'additional_ignore.txt')

    gitignore_patterns = get_gitignore_patterns(base_dir)
    additional_ignore_patterns = get_ignore_patterns(additional_ignore_path)
    patterns = list(set(gitignore_patterns + additional_ignore_patterns))

    open(overview_filename, 'w').close()
    open(detailed_filename, 'w').close()
    open(log_filename, 'w').close()

    with open(overview_filename, 'a', encoding='utf-8') as overview_file, \
         open(detailed_filename, 'a', encoding='utf-8') as detailed_file, \
         open(log_filename, 'a', encoding='utf-8') as logfile:
         
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, script_dir)
                
                if should_include(relative_path, patterns):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as infile:
                            detailed_file.write(f"File: {relative_path}\n")
                            detailed_file.write(infile.read())
                            detailed_file.write("\n\n")
                            logfile.write(f"Including file: {relative_path}\n")
                    except UnicodeDecodeError as e:
                        logfile.write(f"Could not read file (encoding issue) {file_path}: {e}\n")
                    except Exception as e:
                        logfile.write(f"Could not read file {file_path}: {e}\n")
                else:
                    logfile.write(f"Excluded by pattern: {relative_path}\n")
        
        for root, dirs, files in os.walk(script_dir):
            if '.git' in root:
                continue
            dirs[:] = [d for d in dirs if should_include(os.path.relpath(os.path.join(root, d), script_dir), patterns)]
            relative_path = os.path.relpath(root, script_dir)
            if should_include(relative_path, patterns):
                overview_file.write(f"Directory: {relative_path}\n")
                overview_file.write("Contains:\n")
                for dir in dirs:
                    overview_file.write(f"- {dir}\n")
                for file in files:
                    file_relative_path = os.path.relpath(os.path.join(root, file), script_dir)
                    if should_include(file_relative_path, patterns):
                        overview_file.write(f"- {file}\n")
                overview_file.write("\n")
            else:
                logfile.write(f"Excluded directory by pattern: {relative_path}\n")

if __name__ == "__main__":
    base_dir = sys.argv[1] if len(sys.argv) > 1 else '.'
    collect_project_files(base_dir)

File: tools/scripts/codes_by_folders.py


File: tools/data/scanned_project_files/tree.txt


File: .devcontainer/devcontainer.json
// For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:
// https://github.com/microsoft/vscode-dev-containers/tree/v0.209.6/containers/python-3
{
    "image": "mcr.microsoft.com/devcontainers/python:3.11-bullseye",
    "customizations": {
        "codespaces": {
          "openFiles": [
            "README.md",
            "Home.py"
          ]
        },
        "vscode": {
          "settings": {},
          "extensions": [
            "ms-python.python",
            "ms-python.vscode-pylance"
          ]
        }
      },
    "forwardPorts": [
        8501
    ],
    "postCreateCommand": "pip3 install --user -r requirements.txt",
    "postAttachCommand": {
        "server": "streamlit run Home.py --server.enableCORS false --server.enableXsrfProtection false"
    },
    "portsAttributes": {
        "8501": {
            "label": "Application",
            "onAutoForward": "openPreview"
        }
    },
    "remoteUser": "vscode"
}

File: assets/Chinook.db
File: config/__init__.py


File: config/settings.py
# config/settings.py
from pydantic_settings import BaseSettings
from pydantic import SecretStr

class Settings(BaseSettings):
    OPENAI_API_KEY: SecretStr
    OLLAMA_ENDPOINT: str = "http://localhost:11434"
    DEFAULT_MODEL: str = "gpt-4o-mini"
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

settings = Settings()

File: pages/3_🌐_chatbot_with_internet_access.py
import utils
import streamlit as st
from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import Tool
from loguru import logger
from config.settings import settings

st.set_page_config(page_title="인터넷 챗봇", page_icon="🌐")
st.header('인터넷 접근이 가능한 챗봇')
st.write('인터넷 접근 기능을 갖추어 최신 이벤트에 대한 질문에 답변할 수 있습니다.')

class InternetChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()

    @st.cache_resource(show_spinner='연결 중..')
    def setup_agent(_self):
        # 도구 정의
        ddg_search = DuckDuckGoSearchRun()
        tools = [
            Tool(
                name="DuckDuckGoSearch",
                func=ddg_search.run,
                description="현재 사건에 대한 질문에 답할 때 유용합니다. 구체적인 질문을 해야 합니다.",
            )
        ]

        # 프롬프트 가져오기
        prompt = hub.pull("hwchase17/react-chat")

        # LLM 및 에이전트 설정
        memory = ConversationBufferMemory(memory_key="chat_history")
        agent = create_react_agent(_self.llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)
        return agent_executor, memory

    @utils.enable_chat_history
    def main(self):
        agent_executor, memory = self.setup_agent()
        user_query = st.chat_input(placeholder="무엇이든 물어보세요!")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamlitCallbackHandler(st.container())
                try:
                    result = agent_executor.invoke(
                        {"input": user_query, "chat_history": memory.chat_memory.messages},
                        {"callbacks": [st_cb]}
                    )
                    response = result["output"]
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.write(response)
                    
                    # 검색 결과 출처 표시 (있는 경우)
                    if "source" in result:
                        st.info(f"정보 출처: {result['source']}")
                    
                    logger.info(f"사용자 질문: {user_query}")
                    logger.info(f"챗봇 응답: {response}")
                except Exception as e:
                    error_msg = f"응답 생성 중 오류 발생: {str(e)}"
                    st.error(error_msg)
                    logger.error(error_msg)

if __name__ == "__main__":
    st.sidebar.title("설정")
    search_engine = st.sidebar.selectbox("검색 엔진", ["DuckDuckGo", "Google", "Bing"])
    max_search_results = st.sidebar.slider("최대 검색 결과 수", 1, 10, 3)
    
    obj = InternetChatbot()
    obj.main()

File: pages/4_📄_chat_with_your_documents.py
import os
import utils
import streamlit as st
from streaming import StreamHandler
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import DocArrayInMemorySearch
from langchain_text_splitters import RecursiveCharacterTextSplitter
from loguru import logger
from config.settings import settings

st.set_page_config(page_title="문서 챗봇", page_icon="📄")
st.header('문서 기반 챗봇 (기본 RAG)')
st.write('사용자 정의 문서에 접근하여 문서 내용을 참조해 사용자 질문에 답변할 수 있습니다.')

class CustomDataChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()

    def save_file(self, file):
        folder = 'tmp'
        if not os.path.exists(folder):
            os.makedirs(folder)
        
        file_path = f'./{folder}/{file.name}'
        with open(file_path, 'wb') as f:
            f.write(file.getvalue())
        return file_path

    @st.spinner('문서 분석 중..')
    def setup_qa_chain(self, uploaded_files):
        try:
            # 문서 로드
            docs = []
            for file in uploaded_files:
                file_path = self.save_file(file)
                loader = PyPDFLoader(file_path)
                docs.extend(loader.load())
                os.remove(file_path)  # 임시 파일 삭제
            
            # 문서 분할
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            splits = text_splitter.split_documents(docs)

            # 임베딩 생성 및 벡터 DB 저장
            embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")
            vectordb = DocArrayInMemorySearch.from_documents(splits, embeddings)

            # 검색기 정의
            retriever = vectordb.as_retriever(
                search_type='mmr',
                search_kwargs={'k': self.k, 'fetch_k': self.fetch_k}
            )

            # 컨텍스트 대화를 위한 메모리 설정        
            memory = ConversationBufferMemory(
                memory_key='chat_history',
                output_key='answer',
                return_messages=True
            )

            # LLM 및 QA 체인 설정
            qa_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=retriever,
                memory=memory,
                return_source_documents=True,
                verbose=True
            )
            return qa_chain
        except Exception as e:
            logger.error(f"QA 체인 설정 중 오류 발생: {str(e)}")
            raise

    @utils.enable_chat_history
    def main(self):
        # 사용자 입력
        uploaded_files = st.sidebar.file_uploader(label='PDF 파일 업로드', type=['pdf'], accept_multiple_files=True)
        if not uploaded_files:
            st.error("계속하려면 PDF 문서를 업로드해주세요!")
            st.stop()

        # 사용자 설정
        self.k = st.sidebar.slider("검색할 문서 수", 1, 5, 2)
        self.fetch_k = st.sidebar.slider("후보 문서 수", 1, 10, 4)

        user_query = st.chat_input(placeholder="무엇이든 물어보세요!")

        if uploaded_files and user_query:
            try:
                qa_chain = self.setup_qa_chain(uploaded_files)
                utils.display_msg(user_query, 'user')

                with st.chat_message("assistant"):
                    st_cb = StreamHandler(st.empty())
                    result = qa_chain.invoke(
                        {"question": user_query},
                        {"callbacks": [st_cb]}
                    )
                    response = result["answer"]
                    st.session_state.messages.append({"role": "assistant", "content": response})

                    # 참조 표시
                    for idx, doc in enumerate(result['source_documents'], 1):
                        filename = os.path.basename(doc.metadata['source'])
                        page_num = doc.metadata['page']
                        ref_title = f":blue[참조 {idx}: *{filename} - 페이지 {page_num}*]"
                        with st.popover(ref_title):
                            st.caption(doc.page_content)

                logger.info(f"사용자 질문: {user_query}")
                logger.info(f"챗봇 응답: {response}")
            except Exception as e:
                error_msg = f"응답 생성 중 오류 발생: {str(e)}"
                st.error(error_msg)
                logger.error(error_msg)

if __name__ == "__main__":
    obj = CustomDataChatbot()
    obj.main()

File: pages/5_🛢_chat_with_sql_db.py
import utils
import sqlite3
import streamlit as st
from pathlib import Path
from sqlalchemy import create_engine
from loguru import logger
from config.settings import settings

from langchain_openai import ChatOpenAI
from langchain_community.agent_toolkits import create_sql_agent
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.utilities.sql_database import SQLDatabase

st.set_page_config(page_title="SQL 챗봇", page_icon="🛢")
st.header('SQL 데이터베이스와 대화하기')
st.write('간단한 대화형 명령을 통해 SQL 데이터베이스와 상호작용할 수 있는 챗봇입니다.')

class SqlChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
    
    def setup_db(self, db_uri):
        try:
            if db_uri == 'USE_SAMPLE_DB':
                db_filepath = (Path(__file__).parent.parent / "assets/Chinook.db").absolute()
                db_uri = f"sqlite:////{db_filepath}"
                creator = lambda: sqlite3.connect(f"file:{db_filepath}?mode=ro", uri=True)
                db = SQLDatabase(create_engine("sqlite:///", creator=creator))
            else:
                db = SQLDatabase.from_uri(database_uri=db_uri)
            
            with st.sidebar.expander('데이터베이스 테이블', expanded=True):
                st.info('\n- '+'\n- '.join(db.get_usable_table_names()))
            return db
        except Exception as e:
            logger.error(f"데이터베이스 설정 중 오류 발생: {str(e)}")
            st.error(f"데이터베이스 연결 중 오류가 발생했습니다: {str(e)}")
            st.stop()
    
    def setup_sql_agent(self, db):
        try:
            agent = create_sql_agent(
                llm=self.llm,
                db=db,
                top_k=10,
                verbose=True,
                agent_type="openai-tools",
                handle_parsing_errors=True,
                handle_sql_errors=True
            )
            return agent
        except Exception as e:
            logger.error(f"SQL 에이전트 설정 중 오류 발생: {str(e)}")
            st.error(f"SQL 에이전트 설정 중 오류가 발생했습니다: {str(e)}")
            st.stop()

    @utils.enable_chat_history
    def main(self):
        # 사용자 입력
        radio_opt = ['샘플 DB 사용 - Chinook.db', '사용자 SQL DB 연결']
        selected_opt = st.sidebar.radio(
            label='옵션 선택',
            options=radio_opt
        )
        if radio_opt.index(selected_opt) == 1:
            with st.sidebar.popover(':orange[⚠️ 보안 주의사항]', use_container_width=True):
                warning = "SQL 데이터베이스의 Q&A 시스템을 구축하려면 모델이 생성한 SQL 쿼리를 실행해야 합니다. 이 과정에는 고유한 위험이 있습니다. 데이터베이스 연결 권한이 체인/에이전트의 필요에 맞게 항상 최소한으로 제한되어 있는지 확인하세요.\n\n일반적인 보안 모범 사례에 대한 자세한 내용은 [여기](https://python.langchain.com/docs/security)를 참조하세요."
                st.warning(warning)
            db_uri = st.sidebar.text_input(
                label='데이터베이스 URI',
                placeholder='mysql://user:pass@hostname:port/db'
            )
        else:
            db_uri = 'USE_SAMPLE_DB'
        
        if not db_uri:
            st.error("계속하려면 데이터베이스 URI를 입력하세요!")
            st.stop()
        
        db = self.setup_db(db_uri)
        agent = self.setup_sql_agent(db)

        user_query = st.chat_input(placeholder="무엇이든 물어보세요!")

        if user_query:
            st.session_state.messages.append({"role": "user", "content": user_query})
            st.chat_message("user").write(user_query)

            with st.chat_message("assistant"):
                st_cb = StreamlitCallbackHandler(st.container())
                try:
                    result = agent.invoke(
                        {"input": user_query},
                        {"callbacks": [st_cb]}
                    )
                    response = result["output"]
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.write(response)
                    logger.info(f"사용자 질문: {user_query}")
                    logger.info(f"챗봇 응답: {response}")
                except Exception as e:
                    error_msg = f"응답 생성 중 오류 발생: {str(e)}"
                    st.error(error_msg)
                    logger.error(error_msg)

if __name__ == "__main__":
    obj = SqlChatbot()
    obj.main()

File: pages/2_⭐_context_aware_chatbot.py
import utils
import streamlit as st
from streaming import StreamHandler
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from loguru import logger
from config.settings import settings

st.set_page_config(page_title="컨텍스트 인식 챗봇", page_icon="⭐")
st.header('컨텍스트 인식 챗봇')
st.write('컨텍스트 인식을 통한 챗봇 상호작용 향상')

class ContextChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
    
    @st.cache_resource
    def setup_chain(_self, max_tokens=1000):
        memory = ConversationBufferMemory(max_token_limit=max_tokens)
        chain = ConversationChain(llm=_self.llm, memory=memory, verbose=True)
        return chain
    
    @utils.enable_chat_history
    def main(self):
        max_tokens = st.sidebar.slider("메모리 크기 (토큰)", 100, 2000, 1000)
        chain = self.setup_chain(max_tokens)
        user_query = st.chat_input(placeholder="무엇이든 물어보세요!")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                try:
                    result = chain.invoke(
                        {"input": user_query},
                        {"callbacks": [st_cb]}
                    )
                    response = result["response"]
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    logger.info(f"사용자 질문: {user_query}")
                    logger.info(f"챗봇 응답: {response}")
                except Exception as e:
                    error_msg = f"응답 생성 중 오류 발생: {str(e)}"
                    st.error(error_msg)
                    logger.error(error_msg)

if __name__ == "__main__":
    st.sidebar.title("설정")
    model = st.sidebar.selectbox("LLM 모델 선택", [settings.DEFAULT_MODEL, "다른모델1", "다른모델2"])
    temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.7)
    
    obj = ContextChatbot()
    obj.main()

File: pages/1_💬_basic_chatbot.py
import utils
import streamlit as st
from streaming import StreamHandler
from langchain.chains import ConversationChain
from loguru import logger
from config.settings import settings

st.set_page_config(page_title="챗봇", page_icon="💬")
st.header('기본 챗봇')
st.write('LLM과 상호작용할 수 있는 기본 챗봇입니다.')

class BasicChatbot:
    def __init__(self):
        utils.sync_st_session()
        self.llm = utils.configure_llm()
    
    def setup_chain(self):
        chain = ConversationChain(llm=self.llm, verbose=True)
        return chain
    
    @utils.enable_chat_history
    def main(self):
        chain = self.setup_chain()
        user_query = st.chat_input(placeholder="무엇이든 물어보세요!")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                try:
                    result = chain.invoke(
                        {"input": user_query},
                        {"callbacks": [st_cb]}
                    )
                    response = result["response"]
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    logger.info(f"사용자 질문: {user_query}")
                    logger.info(f"챗봇 응답: {response}")
                except Exception as e:
                    error_msg = f"응답 생성 중 오류 발생: {str(e)}"
                    st.error(error_msg)
                    logger.error(error_msg)

if __name__ == "__main__":
    st.sidebar.title("설정")
    model = st.sidebar.selectbox("LLM 모델 선택", [settings.DEFAULT_MODEL, "다른모델1", "다른모델2"])
    temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.7)
    
    obj = BasicChatbot()
    obj.main()

